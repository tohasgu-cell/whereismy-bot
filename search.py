from sentence_transformers import SentenceTransformer
import numpy as np
import logging

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
logging.info("üîç –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞...")
model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')
logging.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

def encode_text(text: str) -> np.ndarray:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ –≤–µ–∫—Ç–æ—Ä (—ç–º–±–µ–¥–¥–∏–Ω–≥) —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 384."""
    return model.encode(text, convert_to_numpy=True)

def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

def rank_ads_by_query(query_embedding: np.ndarray, ads_with_embeddings: list) -> list:
    """
    ads_with_embeddings: —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (ad_row, embedding)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: [(ad_row, similarity), ...], –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ —É–±—ã–≤–∞–Ω–∏—é
    """
    scored = []
    for ad, emb in ads_with_embeddings:
        sim = cosine_similarity(query_embedding, emb)
        scored.append((ad, sim))
    return sorted(scored, key=lambda x: x[1], reverse=True)